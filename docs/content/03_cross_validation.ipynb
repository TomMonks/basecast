{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#suppress ARIMA warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if running in Google Colab install forecast-tools\n",
    "if 'google.colab' in sys.modules:\n",
    "    !pip install forecast-tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.2.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import forecast_tools\n",
    "forecast_tools.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up till now we have used a single validation period to select our best model.  The weakness of that approach is that it gives you a sample size of 1 (that's better than nothing, but generally poor statistics!).  Time series cross validation is an approach to provide more data points when comparing models. In the classicial time series literature time series cross validation is called a **Rolling Forecast Origin**.  There may also be benefit of taking a **sliding window** approach to cross validaiton.  This second approach maintains a fixed sized training set.  I.e. it drops older values from the time series during validation.\n",
    "\n",
    "## Rolling Forecast Origin\n",
    "\n",
    "The following code and output provide a simplified view of how rolling forecast horizons work in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_forecast_origin(train, min_train_size, horizon):\n",
    "    '''\n",
    "    Rolling forecast origin generator.\n",
    "    '''\n",
    "    for i in range(len(train) - min_train_size - horizon + 1):\n",
    "        split_train = train[:min_train_size+i]\n",
    "        split_val = train[min_train_size+i:min_train_size+i+horizon]\n",
    "        yield split_train, split_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full training set: [2502, 2414, 2800, 2143, 2708, 1900, 2333, 2222]\n",
      "hidden test set: [1234, 3456]\n"
     ]
    }
   ],
   "source": [
    "full_series = [2502, 2414, 2800, 2143, 2708, 1900, 2333, 2222, 1234, 3456]\n",
    "\n",
    "test = full_series[-2:]\n",
    "train = full_series[:-2]\n",
    "print('full training set: {0}'.format(train))\n",
    "print('hidden test set: {0}'.format(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object rolling_forecast_origin at 0x7f37236efe40>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_rolling = rolling_forecast_origin(train, min_train_size=4, horizon=2)\n",
    "cv_rolling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV[1]\n",
      "Train:\t[2502, 2414, 2800, 2143]\n",
      "Val:\t[2708, 1900]\n",
      "-----\n",
      "CV[2]\n",
      "Train:\t[2502, 2414, 2800, 2143, 2708]\n",
      "Val:\t[1900, 2333]\n",
      "-----\n",
      "CV[3]\n",
      "Train:\t[2502, 2414, 2800, 2143, 2708, 1900]\n",
      "Val:\t[2333, 2222]\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for cv_train, cv_val in cv_rolling:\n",
    "    print(f'CV[{i+1}]')\n",
    "    print(f'Train:\\t{cv_train}')\n",
    "    print(f'Val:\\t{cv_val}')\n",
    "    print('-----')\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sliding Window Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(train, window_size, horizon, step=1):\n",
    "    '''\n",
    "    sliding window  generator.\n",
    "    \n",
    "    Parameters:\n",
    "    --------\n",
    "    train: array-like\n",
    "        training data for time series method\n",
    "    \n",
    "    window_size: int\n",
    "        lookback - how much data to include.\n",
    "    \n",
    "    horizon: int\n",
    "        forecast horizon\n",
    "        \n",
    "    step: int, optional (default=1)\n",
    "        step=1 means that a single additional data point is added to the time\n",
    "        series.  increase step to run less splits.\n",
    "        \n",
    "    Returns:\n",
    "        array-like, array-like\n",
    "    \n",
    "        split_training, split_validation\n",
    "    '''\n",
    "    for i in range(0, len(train) - window_size - horizon + 1, step):\n",
    "        split_train = train[i:window_size+i]\n",
    "        split_val = train[i+window_size:window_size+i+horizon]\n",
    "        yield split_train, split_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code tests its with `step=1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full training set: [2502, 2414, 2800, 2143, 2708, 1900, 2333, 2222]\n",
      "\n",
      "CV[1]\n",
      "Train:\t[2502, 2414, 2800, 2143]\n",
      "Val:\t[2708]\n",
      "-----\n",
      "CV[2]\n",
      "Train:\t[2414, 2800, 2143, 2708]\n",
      "Val:\t[1900]\n",
      "-----\n",
      "CV[3]\n",
      "Train:\t[2800, 2143, 2708, 1900]\n",
      "Val:\t[2333]\n",
      "-----\n",
      "CV[4]\n",
      "Train:\t[2143, 2708, 1900, 2333]\n",
      "Val:\t[2222]\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "cv_sliding = sliding_window(train, window_size=4, horizon=1)\n",
    "\n",
    "print('full training set: {0}\\n'.format(train))\n",
    "\n",
    "i = 0\n",
    "for cv_train, cv_val in cv_sliding:\n",
    "    print(f'CV[{i+1}]')\n",
    "    print(f'Train:\\t{cv_train}')\n",
    "    print(f'Val:\\t{cv_val}')\n",
    "    print('-----')\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code tests it with `step=2`.  Note that you get less splits.  The code is less computationally expensive at the cost of less data.  That is probably okay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full training set: [2502, 2414, 2800, 2143, 2708, 1900, 2333, 2222]\n",
      "\n",
      "CV[1]\n",
      "Train:\t[2502, 2414, 2800, 2143]\n",
      "Val:\t[2708]\n",
      "-----\n",
      "CV[2]\n",
      "Train:\t[2800, 2143, 2708, 1900]\n",
      "Val:\t[2333]\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "cv_sliding = sliding_window(train, window_size=4, horizon=1, step=2)\n",
    "\n",
    "print('full training set: {0}\\n'.format(train))\n",
    "\n",
    "i = 0\n",
    "for cv_train, cv_val in cv_sliding:\n",
    "    print(f'CV[{i+1}]')\n",
    "    print(f'Train:\\t{cv_train}')\n",
    "    print(f'Val:\\t{cv_val}')\n",
    "    print('-----')\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel Cross Validation Example using Naive1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from forecast_tools.baseline import SNaive, Naive1\n",
    "from forecast_tools.datasets import load_emergency_dept\n",
    "#optimised version of the functions above...\n",
    "from forecast_tools.model_selection import (rolling_forecast_origin, \n",
    "                                            sliding_window,\n",
    "                                            cross_validation_score)\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = load_emergency_dept()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Naive1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%timeit runs the code multiple times to get an estimate of runtime.\n",
    "#comment if out to run the code only once."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run on a single core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:2\u001b[0m\n",
      "File \u001b[0;32m~/miniforge3/envs/forecast_dev/lib/python3.11/site-packages/forecast_tools/model_selection.py:183\u001b[0m, in \u001b[0;36mcross_validation_score\u001b[0;34m(model, cv, metric, horizons, n_jobs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     cv_scores \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m    174\u001b[0m         Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs)(delayed(forecast_accuracy)(model,\n\u001b[1;32m    175\u001b[0m                                                            cv_train,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    178\u001b[0m                                                            metric)\n\u001b[1;32m    179\u001b[0m                                 \u001b[38;5;28;01mfor\u001b[39;00m cv_train, cv_test \u001b[38;5;129;01min\u001b[39;00m cv)\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    182\u001b[0m     cv_scores \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m--> 183\u001b[0m         \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mforecast_accuracy\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m                                                           \u001b[49m\u001b[43mcv_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m                                                           \u001b[49m\u001b[43mcv_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m                                                           \u001b[49m\u001b[43mhorizons\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m                                                           \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m                                \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcv_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv_test\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(cv_scores)\n",
      "File \u001b[0;32m~/miniforge3/envs/forecast_dev/lib/python3.11/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/forecast_dev/lib/python3.11/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/forecast_dev/lib/python3.11/site-packages/joblib/parallel.py:1754\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_retrieval():\n\u001b[1;32m   1748\u001b[0m \n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[1;32m   1751\u001b[0m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[1;32m   1752\u001b[0m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[0;32m-> 1754\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1755\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1757\u001b[0m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/forecast_dev/lib/python3.11/site-packages/joblib/parallel.py:1789\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1785\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediately raise the error by\u001b[39;00m\n\u001b[1;32m   1786\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[1;32m   1788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1789\u001b[0m     \u001b[43merror_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/forecast_dev/lib/python3.11/site-packages/joblib/parallel.py:745\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    739\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_backend\n\u001b[1;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[1;32m    742\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[1;32m    743\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[1;32m    744\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[0;32m--> 745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/forecast_dev/lib/python3.11/site-packages/joblib/parallel.py:763\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    762\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[0;32m--> 763\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[1;32m    764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[1;32m    765\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/forecast_dev/lib/python3.11/site-packages/joblib/parallel.py:1469\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m   1466\u001b[0m big_batch_size \u001b[38;5;241m=\u001b[39m batch_size \u001b[38;5;241m*\u001b[39m n_jobs\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1469\u001b[0m     islice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mitertools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mislice\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbig_batch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1470\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1471\u001b[0m     \u001b[38;5;66;03m# Handle the fact that the generator of task raised an\u001b[39;00m\n\u001b[1;32m   1472\u001b[0m     \u001b[38;5;66;03m# exception. As this part of the code can be executed in\u001b[39;00m\n\u001b[1;32m   1473\u001b[0m     \u001b[38;5;66;03m# a thread internal to the backend, register a task with\u001b[39;00m\n\u001b[1;32m   1474\u001b[0m     \u001b[38;5;66;03m# an error that will be raised in the user's thread.\u001b[39;00m\n\u001b[1;32m   1475\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39m__context__, queue\u001b[38;5;241m.\u001b[39mEmpty):\n\u001b[1;32m   1476\u001b[0m         \u001b[38;5;66;03m# Suppress the cause of the exception if it is\u001b[39;00m\n\u001b[1;32m   1477\u001b[0m         \u001b[38;5;66;03m# queue.Empty to avoid cluttered traceback. Only do it\u001b[39;00m\n\u001b[1;32m   1478\u001b[0m         \u001b[38;5;66;03m# if the __context__ is really empty to avoid messing\u001b[39;00m\n\u001b[1;32m   1479\u001b[0m         \u001b[38;5;66;03m# with causes of the original error.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/forecast_dev/lib/python3.11/site-packages/forecast_tools/model_selection.py:188\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    173\u001b[0m     cv_scores \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m    174\u001b[0m         Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs)(delayed(forecast_accuracy)(model,\n\u001b[1;32m    175\u001b[0m                                                            cv_train,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    178\u001b[0m                                                            metric)\n\u001b[1;32m    179\u001b[0m                                 \u001b[38;5;28;01mfor\u001b[39;00m cv_train, cv_test \u001b[38;5;129;01min\u001b[39;00m cv)\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    182\u001b[0m     cv_scores \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m    183\u001b[0m         Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs)(delayed(forecast_accuracy)(model,\n\u001b[1;32m    184\u001b[0m                                                            cv_train,\n\u001b[1;32m    185\u001b[0m                                                            cv_test,\n\u001b[1;32m    186\u001b[0m                                                            horizons,\n\u001b[1;32m    187\u001b[0m                                                            metric)\n\u001b[0;32m--> 188\u001b[0m                                 \u001b[38;5;28;01mfor\u001b[39;00m cv_train, cv_test \u001b[38;5;129;01min\u001b[39;00m cv)\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(cv_scores)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cv = sliding_window(train, window_size=14, horizon=7, step=1)\n",
    "results_1 = cross_validation_score(model, train, cv, mean_absolute_error, \n",
    "                                   n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run across multiple cores by setting `n_jobs=-1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:2\u001b[0m\n",
      "File \u001b[0;32m~/miniforge3/envs/forecast_dev/lib/python3.11/site-packages/forecast_tools/model_selection.py:183\u001b[0m, in \u001b[0;36mcross_validation_score\u001b[0;34m(model, cv, metric, horizons, n_jobs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     cv_scores \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m    174\u001b[0m         Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs)(delayed(forecast_accuracy)(model,\n\u001b[1;32m    175\u001b[0m                                                            cv_train,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    178\u001b[0m                                                            metric)\n\u001b[1;32m    179\u001b[0m                                 \u001b[38;5;28;01mfor\u001b[39;00m cv_train, cv_test \u001b[38;5;129;01min\u001b[39;00m cv)\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    182\u001b[0m     cv_scores \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m--> 183\u001b[0m         \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mforecast_accuracy\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m                                                           \u001b[49m\u001b[43mcv_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m                                                           \u001b[49m\u001b[43mcv_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m                                                           \u001b[49m\u001b[43mhorizons\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m                                                           \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m                                \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcv_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv_test\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(cv_scores)\n",
      "File \u001b[0;32m~/miniforge3/envs/forecast_dev/lib/python3.11/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/forecast_dev/lib/python3.11/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/forecast_dev/lib/python3.11/site-packages/joblib/parallel.py:1754\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_retrieval():\n\u001b[1;32m   1748\u001b[0m \n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[1;32m   1751\u001b[0m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[1;32m   1752\u001b[0m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[0;32m-> 1754\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1755\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1757\u001b[0m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/forecast_dev/lib/python3.11/site-packages/joblib/parallel.py:1789\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1785\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediately raise the error by\u001b[39;00m\n\u001b[1;32m   1786\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[1;32m   1788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1789\u001b[0m     \u001b[43merror_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/forecast_dev/lib/python3.11/site-packages/joblib/parallel.py:745\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    739\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_backend\n\u001b[1;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[1;32m    742\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[1;32m    743\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[1;32m    744\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[0;32m--> 745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/forecast_dev/lib/python3.11/site-packages/joblib/parallel.py:763\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    762\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[0;32m--> 763\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[1;32m    764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[1;32m    765\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/forecast_dev/lib/python3.11/site-packages/joblib/parallel.py:1469\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m   1466\u001b[0m big_batch_size \u001b[38;5;241m=\u001b[39m batch_size \u001b[38;5;241m*\u001b[39m n_jobs\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1469\u001b[0m     islice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mitertools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mislice\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbig_batch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1470\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1471\u001b[0m     \u001b[38;5;66;03m# Handle the fact that the generator of task raised an\u001b[39;00m\n\u001b[1;32m   1472\u001b[0m     \u001b[38;5;66;03m# exception. As this part of the code can be executed in\u001b[39;00m\n\u001b[1;32m   1473\u001b[0m     \u001b[38;5;66;03m# a thread internal to the backend, register a task with\u001b[39;00m\n\u001b[1;32m   1474\u001b[0m     \u001b[38;5;66;03m# an error that will be raised in the user's thread.\u001b[39;00m\n\u001b[1;32m   1475\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39m__context__, queue\u001b[38;5;241m.\u001b[39mEmpty):\n\u001b[1;32m   1476\u001b[0m         \u001b[38;5;66;03m# Suppress the cause of the exception if it is\u001b[39;00m\n\u001b[1;32m   1477\u001b[0m         \u001b[38;5;66;03m# queue.Empty to avoid cluttered traceback. Only do it\u001b[39;00m\n\u001b[1;32m   1478\u001b[0m         \u001b[38;5;66;03m# if the __context__ is really empty to avoid messing\u001b[39;00m\n\u001b[1;32m   1479\u001b[0m         \u001b[38;5;66;03m# with causes of the original error.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/forecast_dev/lib/python3.11/site-packages/forecast_tools/model_selection.py:188\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    173\u001b[0m     cv_scores \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m    174\u001b[0m         Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs)(delayed(forecast_accuracy)(model,\n\u001b[1;32m    175\u001b[0m                                                            cv_train,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    178\u001b[0m                                                            metric)\n\u001b[1;32m    179\u001b[0m                                 \u001b[38;5;28;01mfor\u001b[39;00m cv_train, cv_test \u001b[38;5;129;01min\u001b[39;00m cv)\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    182\u001b[0m     cv_scores \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m    183\u001b[0m         Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs)(delayed(forecast_accuracy)(model,\n\u001b[1;32m    184\u001b[0m                                                            cv_train,\n\u001b[1;32m    185\u001b[0m                                                            cv_test,\n\u001b[1;32m    186\u001b[0m                                                            horizons,\n\u001b[1;32m    187\u001b[0m                                                            metric)\n\u001b[0;32m--> 188\u001b[0m                                 \u001b[38;5;28;01mfor\u001b[39;00m cv_train, cv_test \u001b[38;5;129;01min\u001b[39;00m cv)\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(cv_scores)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "cv = sliding_window(train, window_size=14, horizon=7, step=1)\n",
    "results_2 = cross_validation_score(model, train, cv, mean_absolute_error,\n",
    "                                    n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mresults_1\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results_1' is not defined"
     ]
    }
   ],
   "source": [
    "results_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results_1.mean(), results_1.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "just to illustrate that the results are the same - the difference is runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results_2.mean(), results_2.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation with multiple forecast horizons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizons = [7, 14, 21]\n",
    "cv = sliding_window(train, window_size=14, horizon=max(horizons), step=1)\n",
    "#note that we now pass in the horizons list to cross_val_score\n",
    "results_h = cross_validation_score(model, train, cv, mean_absolute_error,\n",
    "                                   horizons=horizons, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results are returned as numpy array - easy to cast to dataframe and display\n",
    "pd.DataFrame(results_h, columns=['7days', '14days', '21days']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation example using ARIMA - does it speed up when CV run in Parallel?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use ARIMA from pmdarima as that has a similar interface to baseline models.\n",
    "from pmdarima import ARIMA, auto_arima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ato_model = auto_arima(train, suppress_warnings=True, n_jobs=-1, m=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#auto_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create arima model - reasonably complex model\n",
    "#order=(1, 1, 2), seasonal_order=(2, 0, 2, 7)\n",
    "args = {'order':(1, 1, 2), 'seasonal_order':(2, 0, 2, 7)}\n",
    "model = ARIMA(order=args['order'], seasonal_order=args['seasonal_order'],\n",
    "              enforce_stationarity=False, suppress_warnings=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cv = rolling_forecast_origin(train, min_train_size=320, horizon=7)\n",
    "results_1 = cross_validation_score(model, train, cv, mean_absolute_error, \n",
    "                                   n_jobs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "comment out %%timeit to run the code only once!\n",
    "\n",
    "you should see a big improvement in performance.  mine went \n",
    "from 12.3 seconds to 2.4 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cv = rolling_forecast_origin(train, min_train_size=320, horizon=7)\n",
    "results_2 = cross_validation_score(model, train, cv, mean_absolute_error, \n",
    "                                   n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_2.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
